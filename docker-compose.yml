# ---------------------------------------------------------------------------
# PRODUCTION MEDIA SERVER — docker-compose.yml
# Hardware: 48 Cores / 125GB RAM / NVIDIA GPU (Dual Xeon E5-2697 v2)
# Engine:   Docker Compose v2.27.0 (Non-Swarm)
# Network:  External media_network
# DB Tier:  pgvector/pg17 → PgBouncer (mandatory entry point :5432)
# Storage:  ZFS media-tank + ssd-cache + backup-tank | rclone VFS 500GB
# ---------------------------------------------------------------------------

# ===========================================================================
# ANCHORS
# ===========================================================================

x-common-env: &common-env
  PUID: ${PUID:-1000}
  PGID: ${PGID:-1000}
  UMASK: ${UMASK:-002}
  TZ: ${TZ:-America/New_York}

x-health-default: &health-default
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s

x-logging-default: &logging-default
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "5"
    compress: "true"

x-restart-policy: &restart-policy
  restart: unless-stopped

# Base for all standard services
x-service-base: &service-base
  <<: *restart-policy
  pull_policy: if_not_present
  networks: [media_network]
  logging: *logging-default
  ulimits:
    nofile:
      soft: 1048576
      hard: 1048576
  stop_grace_period: 90s

# Base specifically for Postgres (larger shm, longer grace)
x-pg-common: &pg-common
  image: pgvector/pgvector:pg17
  pull_policy: if_not_present
  <<: *restart-policy
  networks: [media_network]
  logging: *logging-default
  shm_size: "2g"
  tmpfs:
    - /tmp
  stop_grace_period: 180s

# Shared PgBouncer dependency block (avoids repetition across all Arr services)
x-pgbouncer-dep: &pgbouncer-dep
  db-ready:
    condition: service_completed_successfully
  pgbouncer:
    condition: service_healthy

# Shared dependency for Arr services that also need rclone mount
x-arr-dep: &arr-dep
  db-ready:
    condition: service_completed_successfully
  pgbouncer:
    condition: service_healthy
  rclone:
    condition: service_healthy


services:

  # ===========================================================================
  # 1) CORE DATABASE
  # ===========================================================================

  postgres:
    <<: *pg-common
    container_name: postgres
    environment:
      <<: *common-env
      POSTGRES_USER: ${MASTER_USER}
      POSTGRES_PASSWORD: ${MASTER_PASSWORD}
      POSTGRES_DB: postgres
    volumes:
      - /mnt/media/postgres:/var/lib/postgresql/data
    # Tuned for 48-core / 125GB host. shared_buffers=32GB, effective_cache=90GB.
    # parallel workers max out all 48 cores; autovacuum uses 6 workers.
    # Data lives on /mnt/media/postgres (ZFS dataset) — snapshot-friendly.
    command: >
      postgres
      -c max_connections=100
      -c shared_buffers=32GB
      -c effective_cache_size=90GB
      -c maintenance_work_mem=2GB
      -c work_mem=32MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c min_wal_size=2GB
      -c max_wal_size=16GB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=300
      -c max_worker_processes=48
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=48
      -c max_parallel_maintenance_workers=4
      -c shared_preload_libraries=pg_stat_statements
      -c pg_stat_statements.max=10000
      -c pg_stat_statements.track=all
      -c autovacuum_max_workers=6
      -c autovacuum_work_mem=-1
      -c autovacuum_vacuum_scale_factor=0.05
      -c autovacuum_analyze_scale_factor=0.02
    deploy:
      resources:
        limits:
          memory: 64G
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "pg_isready -U ${MASTER_USER} -d postgres"]

  pgbouncer:
    <<: *service-base
    container_name: pgbouncer
    image: edoburu/pgbouncer:latest
    environment:
      <<: *common-env
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${MASTER_USER}
      DB_PASSWORD: ${MASTER_PASSWORD}
      AUTH_TYPE: scram-sha-256
      AUTH_USER: ${MASTER_USER}
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 1000
      DEFAULT_POOL_SIZE: 75
      RESERVE_POOL_SIZE: 25
      SERVER_RESET_QUERY: DISCARD ALL
      # Sonarr/Radarr send extra_float_digits AND application_name on connect.
      # Both must be ignored in transaction mode or PgBouncer rejects the packet.
      IGNORE_STARTUP_PARAMETERS: extra_float_digits,application_name
    ports:
      - "127.0.0.1:6432:5432"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "pg_isready -h localhost -p 5432 -U ${MASTER_USER}"]

  nginx-db:
    <<: *service-base
    container_name: nginx-db
    image: jc21/mariadb-aria:latest
    environment:
      <<: *common-env
      MYSQL_ROOT_PASSWORD: ${NPM_MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${NPM_MYSQL_DATABASE:-npm}
      MYSQL_USER: ${NPM_MYSQL_USER:-npm}
      MYSQL_PASSWORD: ${NPM_MYSQL_PASSWORD}
    volumes:
      - /mnt/media/mysql:/var/lib/mysql
    # O_DIRECT bypasses OS page cache — correct for ZFS ARC-managed storage.
    command: [
      "--skip-innodb-doublewrite",
      "--innodb_flush_method=O_DIRECT",
      "--innodb_use_native_aio=1",
      "--innodb_read_io_threads=16",
      "--innodb_write_io_threads=16"
    ]
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "mysqladmin ping -h localhost -uroot -p${NPM_MYSQL_ROOT_PASSWORD} >/dev/null || exit 1"]

  # Sentinel: confirms DB layer is fully ready before dependent services start.
  db-ready:
    image: alpine:3.20
    pull_policy: if_not_present
    networks: [media_network]
    logging: *logging-default
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_healthy
      nginx-db:
        condition: service_healthy
    command: ["sh", "-c", "echo 'DB layer healthy: postgres + pgbouncer + mariadb'"]

  # ===========================================================================
  # 2) STORAGE & SYNC
  # ===========================================================================

  nzbdav:
    <<: *service-base
    container_name: nzbdav
    image: nzbdav/nzbdav:${NZBDAV_TAG:-2026-02-19.dev}
    profiles: [media]
    environment:
      <<: *common-env
      UPGRADE: ${NZBDAV_UPGRADE_TRACK:-0.6.x}
    ports:
      - "3000:3000"
    volumes:
      - /mnt/media/nzbdav/config:/config
      - /mnt:/mnt
    depends_on:
      db-ready:
        condition: service_completed_successfully
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "wget --spider -q http://localhost:3000 || exit 1"]

  rclone:
    <<: *service-base
    container_name: rclone
    image: rclone/rclone:latest
    profiles: [media]
    cap_add: [SYS_ADMIN]
    devices: [/dev/fuse:/dev/fuse]
    security_opt: ["apparmor:unconfined"]
    volumes:
      - /mnt/media/rclone/config:/config/rclone
      - /mnt:/mnt:rshared
      - /mnt/ssd-cache/rclone/cache-nzbdav:/cache
    depends_on:
      nzbdav:
        condition: service_healthy
    # VFS cache on ssd-cache: 500GB max, 4h max age, 64MB chunk read-ahead.
    # --vfs-fast-fingerprint + --no-checksum reduce API calls significantly.
    # WARNING: avoid `find`/`du` on /mnt/nzbdav-data — thrashes VFS cache.
    command: >
      mount nzbdav-data: /mnt/nzbdav-data
      --umask=002
      --allow-other
      --links
      --use-cookies
      --rc
      --rc-addr=localhost:5572
      --rc-no-auth
      --cache-dir=/cache
      --vfs-cache-mode full
      --vfs-cache-max-size ${RCLONE_VFS_CACHE_MAX_SIZE:-500G}
      --vfs-cache-max-age ${RCLONE_VFS_CACHE_MAX_AGE:-4h}
      --vfs-read-chunk-size 64M
      --vfs-read-ahead 512M
      --buffer-size 256M
      --dir-cache-time 1h
      --attr-timeout 1h
      --no-modtime
      --no-checksum
      --vfs-fast-fingerprint
      --async-read=true
      --log-level ${RCLONE_LOG_LEVEL:-INFO}
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "mountpoint -q /mnt/nzbdav-data && rclone rc core/version --rc-addr 127.0.0.1:5572 >/dev/null 2>&1 || exit 1"]

  # ===========================================================================
  # 3) INDEXERS & DOWNLOADERS
  # ===========================================================================

  prowlarr:
    <<: *service-base
    container_name: prowlarr
    image: lscr.io/linuxserver/prowlarr:${PROWLARR_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      PROWLARR__POSTGRES__HOST: pgbouncer
      PROWLARR__POSTGRES__PORT: 5432
      PROWLARR__POSTGRES__MAINDB: ${PROWLARR_DB:-prowlarr_db}
      PROWLARR__POSTGRES__USER: ${PROWLARR_DB_USER:-${MASTER_USER}}
      PROWLARR__POSTGRES__PASSWORD: ${PROWLARR_DB_PASSWORD:-${MASTER_PASSWORD}}
    volumes:
      - /mnt/media/prowlarr:/config
    ports:
      - "9696:9696"
    depends_on: *pgbouncer-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:9696/ >/dev/null || exit 1"]

  # ===========================================================================
  # 4) MEDIA MANAGERS (ARRs)
  # ===========================================================================

  radarr:
    <<: *service-base
    container_name: radarr
    image: lscr.io/linuxserver/radarr:${RADARR_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      RADARR__POSTGRES__HOST: pgbouncer
      RADARR__POSTGRES__PORT: 5432
      RADARR__POSTGRES__MAINDB: ${RADARR_DB:-radarr_db}
      RADARR__POSTGRES__USER: ${RADARR_DB_USER:-${MASTER_USER}}
      RADARR__POSTGRES__PASSWORD: ${RADARR_DB_PASSWORD:-${MASTER_PASSWORD}}
      RADARR_API_KEY: ${RADARR_API_KEY:-}
    ports:
      - "7878:7878"
    volumes:
      - /mnt/media/radarr/data:/config
      - /mnt/nzbdav-data/completed-symlinks/Movies:/downloads
      - /mnt:/mnt:rslave
    depends_on: *arr-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:7878/ >/dev/null || exit 1"]

  sonarr:
    <<: *service-base
    container_name: sonarr
    image: lscr.io/linuxserver/sonarr:${SONARR_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      SONARR__POSTGRES__HOST: pgbouncer
      SONARR__POSTGRES__PORT: 5432
      SONARR__POSTGRES__USER: ${SONARR_DB_USER:-${MASTER_USER}}
      SONARR__POSTGRES__PASSWORD: ${SONARR_DB_PASSWORD:-${MASTER_PASSWORD}}
      SONARR__POSTGRES__MAINDB: ${SONARR_DB:-sonarr}
      SONARR__POSTGRES__LOGDB: ${SONARR_LOG_DB:-sonarr-log}
    ports:
      - "8989:8989"
    volumes:
      - /mnt/media/sonarr/data:/config
      - /mnt/nzbdav-data/completed-symlinks/Series:/downloads
      - /mnt:/mnt:rslave
    depends_on: *arr-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:8989/ >/dev/null || exit 1"]

  sonarr-anime:
    <<: *service-base
    container_name: sonarr-anime
    image: lscr.io/linuxserver/sonarr:${SONARR_ANIME_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      SONARR__POSTGRES__HOST: pgbouncer
      SONARR__POSTGRES__PORT: 5432
      SONARR__POSTGRES__USER: ${SONARR_ANIME_DB_USER:-${MASTER_USER}}
      SONARR__POSTGRES__PASSWORD: ${SONARR_ANIME_DB_PASSWORD:-${MASTER_PASSWORD}}
      SONARR__POSTGRES__MAINDB: ${SONARR_ANIME_DB:-sonarr-anime}
      SONARR__POSTGRES__LOGDB: ${SONARR_ANIME_LOG_DB:-sonarr-anime-log}
    ports:
      - "8990:8989"
    volumes:
      - /mnt/media/sonarranime/data:/config
      - /mnt/nzbdav-data/completed-symlinks/Anime:/downloads
      - /mnt:/mnt:rslave
    depends_on: *arr-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:8989/ >/dev/null || exit 1"]

  lidarr:
    <<: *service-base
    container_name: lidarr
    image: lscr.io/linuxserver/lidarr:${LIDARR_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      LIDARR_USE_POSTGRES: "true"
      LIDARR__POSTGRES__HOST: pgbouncer
      LIDARR__POSTGRES__PORT: 5432
      LIDARR__POSTGRES__USER: ${LIDARR_DB_USER:-${MASTER_USER}}
      LIDARR__POSTGRES__PASSWORD: ${LIDARR_DB_PASSWORD:-${MASTER_PASSWORD}}
      LIDARR__POSTGRES__MAINDB: ${LIDARR_DB:-lidarr}
    ports:
      - "8686:8686"
    volumes:
      - /mnt/media/lidarr/config:/config
      - /mnt/nzbdav-data/completed-symlinks/Music:/downloads
      - /mnt:/mnt:rslave
    depends_on: *arr-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:8686/ >/dev/null || exit 1"]

  whisparr:
    <<: *service-base
    container_name: whisparr
    image: ghcr.io/hotio/whisparr:nightly
    profiles: [media]
    environment:
      <<: *common-env
      WHISPARR__POSTGRES__HOST: pgbouncer
      WHISPARR__POSTGRES__PORT: 5432
      WHISPARR__POSTGRES__MAINDB: ${WHISPARR_DB:-whisparr_db}
      WHISPARR__POSTGRES__USER: ${WHISPARR_DB_USER:-${MASTER_USER}}
      WHISPARR__POSTGRES__PASSWORD: ${WHISPARR_DB_PASSWORD:-${MASTER_PASSWORD}}
      WHISPARR__API_KEY: ${WHISPARR_API_KEY:-}
    ports:
      - "6969:6969"
    volumes:
      - /mnt/media/whisparr/data:/config
      - /mnt:/mnt:rslave
    depends_on: *arr-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:6969/ >/dev/null || exit 1"]

  # ===========================================================================
  # 5) REQUESTS & STATS
  # ===========================================================================

  seerr:
    <<: *service-base
    container_name: seerr
    image: ghcr.io/seerr-team/seerr:${JELLYSEERR_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      DB_TYPE: postgres
      DB_HOST: pgbouncer
      DB_PORT: 5432
      DB_USER: ${JELLYSEERR_DB_USER:-jellyseerr}
      DB_PASS: ${JELLYSEERR_DB_PASSWORD:-jellyseerr}
      DB_NAME: ${JELLYSEERR_DB:-jellyseerr}
      DB_LOG_QUERIES: "false"
      JWT_SECRET: ${JWT_SECRET:-}
    volumes:
      - /mnt/media/jellyseerr/config:/app/config
    ports:
      - "5055:5055"
    depends_on: *pgbouncer-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "wget --spider -q http://localhost:5055/api/v1/status || exit 1"]

  jellystat:
    <<: *service-base
    container_name: jellystat
    image: cyfershepard/jellystat:${JELLYSTAT_TAG:-latest}
    profiles: [media]
    environment:
      <<: *common-env
      POSTGRES_IP: pgbouncer
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${JELLYSTAT_DB:-jfstat}
      POSTGRES_USER: ${JELLYSTAT_DB_USER:-jellystat}
      POSTGRES_PASSWORD: ${JELLYSTAT_DB_PASSWORD:?JELLYSTAT_DB_PASSWORD must be set in .env}
      JWT_SECRET: ${JELLYSTAT_JWT_SECRET:?JELLYSTAT_JWT_SECRET must be set in .env}
    volumes:
      - /mnt/media/jellystat/backup-data:/app/backend/backup-data
    ports:
      - "3002:3000"
    depends_on: *pgbouncer-dep
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "wget --spider -q http://localhost:3000/ || exit 1"]

  # ===========================================================================
  # 6) MEDIA SERVERS / EDGE
  # ===========================================================================

  emby:
    <<: *service-base
    container_name: emby
    image: emby/embyserver:${EMBY_TAG:-latest}
    profiles: [media]
    runtime: nvidia   # GPU mandatory for hardware transcoding
    environment:
      <<: *common-env
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,video,utility
    deploy:
      resources:
        limits:
          cpus: '40'    # Reserve 8 cores for OS + ZFS ARC management
          memory: 48G
    volumes:
      - /mnt/media/embyserver/data:/config
      - /mnt/ssd-cache/emby/cache:/config/cache
      - /mnt/ssd-cache/emby/transcode:/transcode
      - /mnt:/mnt:rslave
    ports:
      - "8096:8096"
    depends_on:
      db-ready:
        condition: service_completed_successfully
      rclone:
        condition: service_healthy
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "wget --spider -q http://localhost:8096/emby/system/info/public || exit 1"]

  nginx:
    <<: *service-base
    container_name: nginx
    image: jc21/nginx-proxy-manager:${NPM_TAG:-latest}
    profiles: [media]
    environment:
      DB_MYSQL_HOST: nginx-db
      DB_MYSQL_PORT: 3306
      DB_MYSQL_USER: ${NPM_MYSQL_USER:-npm}
      DB_MYSQL_PASSWORD: ${NPM_MYSQL_PASSWORD}
      DB_MYSQL_NAME: ${NPM_MYSQL_DATABASE:-npm}
    ports:
      - "80:80"
      - "443:443"
      - "127.0.0.1:81:81"
    volumes:
      - /mnt/media/nginx/data:/data
      - /mnt/media/nginx/letsencrypt:/etc/letsencrypt
    depends_on:
      db-ready:
        condition: service_completed_successfully
      nginx-db:
        condition: service_healthy
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:81/ >/dev/null || exit 1"]

  # ===========================================================================
  # 7) OPS / MONITORING
  # ===========================================================================

  scrutiny:
    <<: *service-base
    container_name: scrutiny
    image: ghcr.io/analogj/scrutiny:${SCRUTINY_TAG:-master-omnibus}
    profiles: [ops]
    cap_add:
      - SYS_RAWIO
    # TODO: Enumerate all ZFS pool drives. Run: lsblk -d -o NAME,SIZE,TYPE | grep disk
    devices:
      - /dev/sda:/dev/sda
      - /dev/sdb:/dev/sdb
      - /dev/sdc:/dev/sdc
    ports:
      - "8081:8080"
    volumes:
      - /run/udev:/run/udev:ro
    depends_on:
      db-ready:
        condition: service_completed_successfully
    healthcheck:
      <<: *health-default
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/api/health >/dev/null || exit 1"]

  netdata:
    <<: *service-base
    container_name: netdata
    image: netdata/netdata:${NETDATA_TAG:-stable}
    profiles: [ops]
    hostname: ${NETDATA_HOSTNAME:-media-server}
    cap_add:
      - SYS_PTRACE
      - SYS_ADMIN
    security_opt:
      - apparmor:unconfined
    ports:
      - "127.0.0.1:19999:19999"
    environment:
      <<: *common-env
      NETDATA_CLAIM_TOKEN: ${NETDATA_CLAIM_TOKEN:-}
      NETDATA_CLAIM_URL: ${NETDATA_CLAIM_URL:-https://app.netdata.cloud}
      NETDATA_CLAIM_ROOMS: ${NETDATA_CLAIM_ROOMS:-}
    volumes:
      - netdataconfig:/etc/netdata
      - netdatalib:/var/lib/netdata
      - netdatacache:/var/cache/netdata
      - /:/host/root:ro,rslave
      - /etc/passwd:/host/etc/passwd:ro
      - /etc/group:/host/etc/group:ro
      - /etc/localtime:/etc/localtime:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /etc/os-release:/host/etc/os-release:ro
      - /var/log:/host/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /run/dbus:/run/dbus:ro

# ===========================================================================
# NETWORKS & VOLUMES
# ===========================================================================

networks:
  media_network:
    external: true

volumes:
  netdataconfig:
  netdatalib:
  netdatacache:
